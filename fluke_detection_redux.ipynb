{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "from fastai.callbacks.hooks import num_features_model\n",
    "from torch.nn import L1Loss\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "import json\n",
    "#import cv2\n",
    "import types\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('../input')\n",
    "train_dir = root_dir/'train'\n",
    "annot_dir = root_dir/'annotation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.load(open(f'{annot_dir}/annotations.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': [{'class': 'fluke',\n",
       "   'height': 372.0,\n",
       "   'type': 'rect',\n",
       "   'width': 1017.0,\n",
       "   'x': 14.0,\n",
       "   'y': 97.0},\n",
       "  {'class': 'left',\n",
       "   'type': 'point',\n",
       "   'x': 50.802273527488566,\n",
       "   'y': 98.58659021176},\n",
       "  {'class': 'notch',\n",
       "   'type': 'point',\n",
       "   'x': 516.2391276137811,\n",
       "   'y': 269.48861474128864},\n",
       "  {'class': 'right',\n",
       "   'type': 'point',\n",
       "   'x': 1013.5305065138045,\n",
       "   'y': 102.10753986218477}],\n",
       " 'class': 'image',\n",
       " 'filename': '6138dce83.jpg'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above annotations are in coco dataset format (x, y, width, height). The fastai library expects bbox coordinates to be in the format of (y_upper_left, x_upper_left, y_lower_right, x_lower_right) with the origin being in the upper left hand corner of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'fluke',\n",
       " 'height': 372.0,\n",
       " 'type': 'rect',\n",
       " 'width': 1017.0,\n",
       " 'x': 14.0,\n",
       " 'y': 97.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0]['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anno2bbox(anno):\n",
    "    im_width, im_height = PIL.Image.open(f\"../input/train/{anno['filename']}\").size\n",
    "    file = anno['filename']\n",
    "    for anno in anno['annotations']:\n",
    "        if anno['class'] == 'fluke':\n",
    "            break\n",
    "    #anno = anno['annotations'][0]\n",
    "    #print(file, anno)\n",
    "    return [\n",
    "        np.clip(anno['y'], 0, im_height) / im_height * SZ,\n",
    "        np.clip(anno['x'], 0, im_width) / im_width * SZ,\n",
    "        np.clip(anno['y']+anno['height'], 0, im_height) / im_height * SZ,\n",
    "        np.clip(anno['x']+anno['width'], 0, im_width) / im_width * SZ\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some small functions that will be helpful as we construct our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2bbox = {jj['filename']: [[anno2bbox(jj)], [anno['class'] for anno in jj['annotations']]] for jj in j}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)\n",
    "get_y_func = lambda o: fn2bbox[path2fn(o)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(o)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[36.21333333333333,\n",
       "   2.986666666666667,\n",
       "   175.09333333333333,\n",
       "   219.9466666666667]],\n",
       " ['fluke', 'left', 'notch', 'right']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2bbox['6138dce83.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(len(j))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(idxs)\n",
    "val_idxs = idxs[:100]\n",
    "# val_idxs = pd.to_pickle(val_idxs, 'data/val_idxs_detection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_j = [anno for i, anno in enumerate(j) if i in val_idxs]\n",
    "trn_j = [anno for i, anno in enumerate(j) if i not in val_idxs]\n",
    "len(trn_j), len(val_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle([anno['filename'] for anno in val_j], f'{annot_dir}/val_fns_detection.pkl') # this will allow me to use the same validation set across NBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fns = pd.read_pickle(f'{annot_dir}/val_fns_detection.pkl') # I create this file in fluke_detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0dcfd05bf.jpg'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_fns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ObjectCategoryList is designed to be used in a full object recognition scenario (multiple bounding boxes per image, objects of multiple classes). Since that is more functionality than we require (and more than our model will predict - our objects will always be of the same class, fluke, and we will be predicting just a single bounding box per image) I make minor changes to ObjectCategoryList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StubbedObjectCategoryList(ObjectCategoryList):\n",
    "    def analyze_pred(self, pred): return [pred.unsqueeze(0), torch.ones(1).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/basic_data.py:215: UserWarning: It's not possible to collate samples of your dataset together in a batch.\n",
      "  warn(message)\n"
     ]
    }
   ],
   "source": [
    "data = (ObjectItemList.from_df(pd.DataFrame(data=list(fn2bbox.keys())), path=train_dir)\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)                         \n",
    "        .label_from_func(get_y_func, label_cls=StubbedObjectCategoryList)\n",
    "        .transform(get_transforms(max_zoom=1, max_warp=0.05, max_rotate=0.05, max_lighting=0.2), tfm_y=True, size=(SZ,SZ), resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 105, in data_collate\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in to_data\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in <listcomp>\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in to_data\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in <listcomp>\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 90, in to_data\n    return b.data if isinstance(b,ItemBase) else b\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/vision/image.py\", line 356, in data\n    bboxes,lbls = self._compute_boxes()\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/vision/image.py\", line 352, in _compute_boxes\n    return res, self.labels[to_np(mask).astype(bool)]\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8a725888fe79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mshow_batch\u001b[0;34m(self, rows, ds_type, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;34m\"Show a batch of data in `ds_type` on a few `rows`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_square_show\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Traceback (most recent call last):\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 105, in data_collate\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in to_data\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in <listcomp>\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in to_data\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 89, in <listcomp>\n    if is_listy(b): return [to_data(o) for o in b]\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/torch_core.py\", line 90, in to_data\n    return b.data if isinstance(b,ItemBase) else b\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/vision/image.py\", line 356, in data\n    bboxes,lbls = self._compute_boxes()\n  File \"/home/wb/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/fastai/vision/image.py\", line 352, in _compute_boxes\n    return res, self.labels[to_np(mask).astype(bool)]\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 1\n"
     ]
    }
   ],
   "source": [
    "data.show_batch(rows=3, ds_type=DatasetType.Valid, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlukeDetector(nn.Module):\n",
    "    def __init__(self, arch=models.resnet18):\n",
    "        super().__init__() \n",
    "        self.cnn = create_body(arch)\n",
    "        self.head = create_head(num_features_model(self.cnn) * 2, 4)\n",
    "        \n",
    "    def forward(self, im):\n",
    "        x = self.cnn(im)\n",
    "        x = self.head(x)\n",
    "        return 2 * (x.sigmoid_() - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, targs, class_idxs):\n",
    "    return L1Loss()(preds, targs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, FlukeDetector(arch=models.resnet50), loss_func=loss_fn)\n",
    "learn.metrics = [lambda preds, targs, _: IoU(preds, targs.squeeze()).mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.split([learn.model.cnn[:6], learn.model.cnn[6:], learn.model.head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 2e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(40, lrs, div_factor=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds, targs = learn.get_preds()\n",
    "\n",
    "# predicted_bboxes = ((preds + 1) / 2 * SZ).numpy()\n",
    "# targets = ((targs + 1) / 2 * SZ).numpy().squeeze()\n",
    "\n",
    "# def draw_bbox(img, bbox, target=None, color=(255, 0, 0), thickness=2):\n",
    "#     y_min, x_min, y_max, x_max = map(int, bbox)\n",
    "#     cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "#     if target is not None:\n",
    "#         y_min, x_min, y_max, x_max = map(int, target)\n",
    "#         cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=(0,255,0), thickness=thickness)\n",
    "#     return img\n",
    "\n",
    "# def cv_read(path):    \n",
    "#     im = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "#     return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Targets are in green, predictions in red.\n",
    "# ims = np.stack([draw_bbox(cv_read(data.valid_ds.items[i]), predicted_bboxes[i], targets[i]) for i in range(9)])\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(montage(np.stack(ims), multichannel=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
