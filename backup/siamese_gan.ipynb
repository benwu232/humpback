{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66456b04405182f1e5583058307f702b130fb40e"
   },
   "source": [
    "## This is my attempt to use siamese with gan idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "906946c5539307d4d006ac922f6516c8ca73973d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_kaggle = 0\n",
    "\n",
    "if use_kaggle:\n",
    "    #!pip install git+https://github.com/fastai/fastai.git\n",
    "    !git clone https://github.com/benwu232/humpback\n",
    "    import sys\n",
    "     # Add directory holding utility functions to path to allow importing utility funcitons\n",
    "    #sys.path.insert(0, '/kaggle/working/protein-atlas-fastai')\n",
    "    sys.path.append('/kaggle/humback/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "de5edc472d60a4712451c4697bcdac9491052942"
   },
   "outputs": [],
   "source": [
    "# Suppress annoying stderr output when importing keras.\n",
    "import sys\n",
    "import platform\n",
    "old_stderr = sys.stderr\n",
    "sys.stderr = open('/dev/null' if platform.system() != 'Windows' else 'nul', 'w')\n",
    "\n",
    "sys.stderr = old_stderr\n",
    "\n",
    "import random\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# Determise the size of each image\n",
    "from os.path import isfile\n",
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy_thresh\n",
    "from fastai.basic_data import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from fastai.callbacks.hooks import num_features_model, model_sizes\n",
    "from fastai.layers import BCEWithLogitsFlat\n",
    "from fastai.basic_train import Learner\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "if use_kaggle:\n",
    "    from humpback.utils import *\n",
    "else:\n",
    "    from utils import *\n",
    "    \n",
    "from IPython.core.debugger import set_trace\n",
    "#from functional import seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "93bb20436b38d8f58ad0d878e279c06ea6f0801e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.44.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2362a475b45c5d126eaf17106cdbfddec1bb3cb2"
   },
   "outputs": [],
   "source": [
    "root_path = Path('../input')\n",
    "train_path = root_path/'train'\n",
    "test_path = root_path/'test'\n",
    "learn_path = Path('../')\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5cb2990ac2fe2a4f733535b1c755afbef35b6f96"
   },
   "outputs": [],
   "source": [
    "#name = f'siamese_resnet34_224'\n",
    "#arch = models.resnet34\n",
    "name = f'siamese_resnet18_224'\n",
    "arch = models.resnet18\n",
    "\n",
    "im_size = 224\n",
    "train_batch_size = 64\n",
    "val_batch_size = 128\n",
    "if use_kaggle:\n",
    "    dl_workers = 0\n",
    "else:\n",
    "    dl_workers = 6\n",
    "SEED=0\n",
    "emb_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f6d315086f994303b0f4d67b4c968621eb437a29"
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../input/train.csv')\n",
    "df_new = df0[df0.Id == 'new_whale']\n",
    "df_known = df0[df0.Id != 'new_whale']\n",
    "train_list, val_list = split_whale_set(df0, nth_fold=0, new_whale_method=1, seed=1)\n",
    "\n",
    "im_count = df0[df0.Id != 'new_whale'].Id.value_counts()\n",
    "im_count.name = 'sighting_count'\n",
    "ex_df = df0.join(im_count, on='Id')\n",
    "\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)\n",
    "fn2label = {row[1].Image: row[1].Id for row in df0.iterrows()}\n",
    "class_dict = make_whale_class_dict(df0)\n",
    "file_lut = df0.set_index('Image').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "12ef302f15102e4b78bda45359e95e9f0ff61a68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5471"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "d203f911cec27d8decb301936c2da0b5e1f09252",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_tfms = get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2)\n",
    "\n",
    "data = (\n",
    "    ImageItemList\n",
    "        # .from_df(df_known, 'data/train', cols=['Image'])\n",
    "        .from_folder(train_path)\n",
    "        # .split_by_idxs(train_item_list, val_item_list)\n",
    "        .split_by_valid_func(lambda path: path2fn(str(path)) in val_list)\n",
    "        # .split_by_idx(val_list)\n",
    "        # .random_split_by_pct(seed=SEED)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(str(path))])\n",
    "        #.add_test(ImageItemList.from_folder(test_path))\n",
    "        #.transform([None, None], size=im_size, resize_method=ResizeMethod.SQUISH)\n",
    "        .transform(im_tfms, size=im_size, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=train_batch_size, num_workers=dl_workers, path=root_path)\n",
    "        #.normalize(imagenet_stats)\n",
    ")\n",
    "\n",
    "data.add_tfm(normalize_batch)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    SiameseDs(data.train_ds, data.train_dl),\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_siamese,\n",
    "    num_workers=dl_workers\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    SiameseDs(data.valid_ds, data.valid_dl),\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_siamese,\n",
    "    num_workers=dl_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "3f8f2d153e9970300574e135c523e1e43b740259"
   },
   "outputs": [],
   "source": [
    "train_bunch = ImageDataBunch(train_dl, val_dl, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "168c45a50e0ea160109e8bc6c2bcb21c8ddc8fd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNet(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): PReLU(num_parameters=1)\n",
       "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#siamese = SiameseNetwork(arch=arch)\n",
    "#siamese = SiameseNet(emb_len=emb_len, arch=arch, forward_type='similarity', drop_rate=0.5)\n",
    "siamese = SiameseNet(emb_len=emb_len, arch=arch, forward_type='distance', drop_rate=0.5)\n",
    "#siamese = SiameseNetwork2(arch=arch)\n",
    "siamese.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "631ad12f3ed69a96e12d4d80ea171e372ad18eb1"
   },
   "outputs": [],
   "source": [
    "learn = Learner(train_bunch,\n",
    "                  siamese,\n",
    "                  #enable_validate=True,\n",
    "                  path=learn_path,\n",
    "                  #loss_func=BCEWithLogitsFlat(),\n",
    "                  loss_func=ContrastiveLoss(margin=contrastive_neg_margin),\n",
    "                  metrics=[avg_pos, avg_neg]\n",
    "                  #metrics=[lambda preds, targs: accuracy_thresh(preds.squeeze(), targs, sigmoid=False)]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "b04638dc94d032ab52162cc29d44e0bc55ae9530"
   },
   "outputs": [],
   "source": [
    "learn.split([learn.model.cnn[:6], learn.model.cnn[6:], learn.model.fc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3db56b21206b303f5ef78632597d61ab9f21280b"
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback\n",
    "cb_save_model = SaveModelCallback(learn, every=\"epoch\", name=name)\n",
    "#cb_siamese_validate = SiameseValidateCallback(learn, txlog)\n",
    "cbs = [cb_save_model]#, cb_siamese_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "596b9aad355f1fce6be5989a717b71c5fab75b8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 12:23 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>avg_pos</th>\n",
       "    <th>avg_neg</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>38.817780</th>\n",
       "    <th>14.141239</th>\n",
       "    <th>14.169743</th>\n",
       "    <th>-7.393423</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>16.999418</th>\n",
       "    <th>4.625903</th>\n",
       "    <th>3.569357</th>\n",
       "    <th>5.697971</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>12.595634</th>\n",
       "    <th>4.682240</th>\n",
       "    <th>2.612115</th>\n",
       "    <th>6.782680</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-1)\n",
    "learn.fit_one_cycle(3)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "1cf65ceea3c1d43f351b2392e755a154774e24a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR plotting ...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 6.31E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "enable_lr_find = 1\n",
    "if enable_lr_find:\n",
    "    print('LR plotting ...')\n",
    "    learn.lr_find()\n",
    "    learn.recorder.plot()\n",
    "    plt.savefig('lr_find.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "ac59fa95808d328cc7574d6be08cd745042a8799"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 6:58:40 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>avg_pos</th>\n",
       "    <th>avg_neg</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>12.515120</th>\n",
       "    <th>4.700226</th>\n",
       "    <th>2.528710</th>\n",
       "    <th>6.903825</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>12.519738</th>\n",
       "    <th>4.672958</th>\n",
       "    <th>2.643437</th>\n",
       "    <th>6.732162</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>12.507962</th>\n",
       "    <th>4.685122</th>\n",
       "    <th>2.597113</th>\n",
       "    <th>6.803691</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>12.497748</th>\n",
       "    <th>4.671924</th>\n",
       "    <th>2.683470</th>\n",
       "    <th>6.689217</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>12.519938</th>\n",
       "    <th>4.678540</th>\n",
       "    <th>2.654346</th>\n",
       "    <th>6.732213</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>12.531446</th>\n",
       "    <th>4.678624</th>\n",
       "    <th>2.646241</th>\n",
       "    <th>6.740745</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>12.506563</th>\n",
       "    <th>4.681217</th>\n",
       "    <th>2.605120</th>\n",
       "    <th>6.787756</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>12.511176</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.682613</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>12.531618</th>\n",
       "    <th>4.692305</th>\n",
       "    <th>2.583071</th>\n",
       "    <th>6.832685</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>12.536766</th>\n",
       "    <th>4.692974</th>\n",
       "    <th>2.580631</th>\n",
       "    <th>6.836294</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>12.543990</th>\n",
       "    <th>4.667481</th>\n",
       "    <th>2.691178</th>\n",
       "    <th>6.672451</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>12.490849</th>\n",
       "    <th>4.689727</th>\n",
       "    <th>2.571056</th>\n",
       "    <th>-872019.875000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>12.524312</th>\n",
       "    <th>4.685619</th>\n",
       "    <th>2.602918</th>\n",
       "    <th>6.798707</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>12.511962</th>\n",
       "    <th>4.685953</th>\n",
       "    <th>2.595945</th>\n",
       "    <th>6.806590</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>12.511546</th>\n",
       "    <th>4.673067</th>\n",
       "    <th>2.647952</th>\n",
       "    <th>6.727911</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>12.527104</th>\n",
       "    <th>4.673153</th>\n",
       "    <th>2.668439</th>\n",
       "    <th>6.707103</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>12.516207</th>\n",
       "    <th>4.661820</th>\n",
       "    <th>2.739359</th>\n",
       "    <th>6.612000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>12.476707</th>\n",
       "    <th>4.695746</th>\n",
       "    <th>2.525570</th>\n",
       "    <th>6.897938</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>12.522529</th>\n",
       "    <th>4.686985</th>\n",
       "    <th>2.595947</th>\n",
       "    <th>6.808630</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>12.540578</th>\n",
       "    <th>4.665808</th>\n",
       "    <th>2.699909</th>\n",
       "    <th>6.660070</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>21</th>\n",
       "    <th>12.493614</th>\n",
       "    <th>4.671898</th>\n",
       "    <th>2.676419</th>\n",
       "    <th>6.696546</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>22</th>\n",
       "    <th>12.516072</th>\n",
       "    <th>4.684131</th>\n",
       "    <th>2.597469</th>\n",
       "    <th>6.801366</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>23</th>\n",
       "    <th>12.517572</th>\n",
       "    <th>4.666741</th>\n",
       "    <th>2.702353</th>\n",
       "    <th>6.659577</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>24</th>\n",
       "    <th>12.513248</th>\n",
       "    <th>4.671158</th>\n",
       "    <th>2.672382</th>\n",
       "    <th>6.699222</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>25</th>\n",
       "    <th>12.495294</th>\n",
       "    <th>4.685864</th>\n",
       "    <th>2.596220</th>\n",
       "    <th>6.806206</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>26</th>\n",
       "    <th>12.508259</th>\n",
       "    <th>4.675694</th>\n",
       "    <th>2.636332</th>\n",
       "    <th>6.744995</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>27</th>\n",
       "    <th>12.507516</th>\n",
       "    <th>4.689297</th>\n",
       "    <th>2.565916</th>\n",
       "    <th>6.843951</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>28</th>\n",
       "    <th>12.511705</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.594168</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>29</th>\n",
       "    <th>12.488188</th>\n",
       "    <th>4.656035</th>\n",
       "    <th>2.750274</th>\n",
       "    <th>6.589494</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>30</th>\n",
       "    <th>12.512432</th>\n",
       "    <th>4.659247</th>\n",
       "    <th>2.723039</th>\n",
       "    <th>6.623498</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>31</th>\n",
       "    <th>12.549042</th>\n",
       "    <th>4.694246</th>\n",
       "    <th>2.573527</th>\n",
       "    <th>6.846163</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>32</th>\n",
       "    <th>12.490520</th>\n",
       "    <th>4.678585</th>\n",
       "    <th>2.630603</th>\n",
       "    <th>6.756647</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>33</th>\n",
       "    <th>12.554338</th>\n",
       "    <th>4.672171</th>\n",
       "    <th>2.657839</th>\n",
       "    <th>6.715921</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>34</th>\n",
       "    <th>12.557899</th>\n",
       "    <th>4.668701</th>\n",
       "    <th>2.669048</th>\n",
       "    <th>6.697401</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>35</th>\n",
       "    <th>12.504217</th>\n",
       "    <th>4.665885</th>\n",
       "    <th>2.678305</th>\n",
       "    <th>6.682513</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>36</th>\n",
       "    <th>12.542370</th>\n",
       "    <th>4.685425</th>\n",
       "    <th>2.590055</th>\n",
       "    <th>6.811574</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>37</th>\n",
       "    <th>12.476370</th>\n",
       "    <th>4.665030</th>\n",
       "    <th>2.699466</th>\n",
       "    <th>6.659198</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>38</th>\n",
       "    <th>12.529338</th>\n",
       "    <th>4.679451</th>\n",
       "    <th>2.641478</th>\n",
       "    <th>6.747261</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>39</th>\n",
       "    <th>12.520090</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.651736</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>40</th>\n",
       "    <th>12.499434</th>\n",
       "    <th>4.687228</th>\n",
       "    <th>2.624509</th>\n",
       "    <th>-7971263741952.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>41</th>\n",
       "    <th>12.518021</th>\n",
       "    <th>4.671623</th>\n",
       "    <th>2.692326</th>\n",
       "    <th>-inf</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>42</th>\n",
       "    <th>12.515675</th>\n",
       "    <th>4.681590</th>\n",
       "    <th>2.624559</th>\n",
       "    <th>6.768737</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>43</th>\n",
       "    <th>12.526964</th>\n",
       "    <th>4.686530</th>\n",
       "    <th>2.592878</th>\n",
       "    <th>6.810786</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>44</th>\n",
       "    <th>12.489287</th>\n",
       "    <th>4.656543</th>\n",
       "    <th>2.735421</th>\n",
       "    <th>6.605532</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>45</th>\n",
       "    <th>12.533875</th>\n",
       "    <th>4.684168</th>\n",
       "    <th>2.573537</th>\n",
       "    <th>-2411554880356352.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>46</th>\n",
       "    <th>12.521787</th>\n",
       "    <th>4.672926</th>\n",
       "    <th>2.659684</th>\n",
       "    <th>-2425395949338624.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>47</th>\n",
       "    <th>12.522464</th>\n",
       "    <th>4.661404</th>\n",
       "    <th>2.736209</th>\n",
       "    <th>6.614313</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>48</th>\n",
       "    <th>12.517894</th>\n",
       "    <th>4.674919</th>\n",
       "    <th>2.644829</th>\n",
       "    <th>6.734629</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>49</th>\n",
       "    <th>12.537128</th>\n",
       "    <th>4.693753</th>\n",
       "    <th>2.545713</th>\n",
       "    <th>-2364896771571712.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>50</th>\n",
       "    <th>12.495283</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.656718</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>51</th>\n",
       "    <th>12.494052</th>\n",
       "    <th>4.671206</th>\n",
       "    <th>2.679554</th>\n",
       "    <th>-1109913501696.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>52</th>\n",
       "    <th>12.515458</th>\n",
       "    <th>4.687393</th>\n",
       "    <th>2.601636</th>\n",
       "    <th>6.803881</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>53</th>\n",
       "    <th>12.501049</th>\n",
       "    <th>4.691514</th>\n",
       "    <th>2.555375</th>\n",
       "    <th>6.859087</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>54</th>\n",
       "    <th>12.547218</th>\n",
       "    <th>4.684299</th>\n",
       "    <th>2.589209</th>\n",
       "    <th>6.810082</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>55</th>\n",
       "    <th>12.530426</th>\n",
       "    <th>4.678654</th>\n",
       "    <th>2.631886</th>\n",
       "    <th>6.755427</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>56</th>\n",
       "    <th>12.523302</th>\n",
       "    <th>4.672215</th>\n",
       "    <th>2.657193</th>\n",
       "    <th>-2068947.750000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>57</th>\n",
       "    <th>12.524518</th>\n",
       "    <th>4.676737</th>\n",
       "    <th>2.645042</th>\n",
       "    <th>6.738205</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>58</th>\n",
       "    <th>12.540682</th>\n",
       "    <th>4.664742</th>\n",
       "    <th>2.702801</th>\n",
       "    <th>6.655150</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>59</th>\n",
       "    <th>12.466394</th>\n",
       "    <th>4.677247</th>\n",
       "    <th>2.615197</th>\n",
       "    <th>6.769608</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>60</th>\n",
       "    <th>12.502310</th>\n",
       "    <th>4.672348</th>\n",
       "    <th>2.667572</th>\n",
       "    <th>6.706427</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>61</th>\n",
       "    <th>12.511099</th>\n",
       "    <th>4.665756</th>\n",
       "    <th>2.699709</th>\n",
       "    <th>6.660423</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>62</th>\n",
       "    <th>12.523796</th>\n",
       "    <th>4.681922</th>\n",
       "    <th>2.608401</th>\n",
       "    <th>6.785834</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>63</th>\n",
       "    <th>12.541493</th>\n",
       "    <th>4.687643</th>\n",
       "    <th>2.594090</th>\n",
       "    <th>6.811917</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>64</th>\n",
       "    <th>12.546435</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.597197</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>65</th>\n",
       "    <th>12.542431</th>\n",
       "    <th>4.673130</th>\n",
       "    <th>2.642014</th>\n",
       "    <th>6.733956</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>66</th>\n",
       "    <th>12.502946</th>\n",
       "    <th>4.682892</th>\n",
       "    <th>2.575478</th>\n",
       "    <th>-8679420928.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>67</th>\n",
       "    <th>12.456950</th>\n",
       "    <th>4.663277</th>\n",
       "    <th>2.690448</th>\n",
       "    <th>6.664783</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>68</th>\n",
       "    <th>12.509756</th>\n",
       "    <th>4.672027</th>\n",
       "    <th>2.637543</th>\n",
       "    <th>6.736187</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>69</th>\n",
       "    <th>12.534347</th>\n",
       "    <th>4.676024</th>\n",
       "    <th>2.640613</th>\n",
       "    <th>6.741214</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>70</th>\n",
       "    <th>12.520507</th>\n",
       "    <th>4.661375</th>\n",
       "    <th>2.739165</th>\n",
       "    <th>6.611410</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>71</th>\n",
       "    <th>12.520446</th>\n",
       "    <th>4.686609</th>\n",
       "    <th>2.584688</th>\n",
       "    <th>6.819394</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>72</th>\n",
       "    <th>12.482475</th>\n",
       "    <th>4.678509</th>\n",
       "    <th>2.635970</th>\n",
       "    <th>6.751015</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>73</th>\n",
       "    <th>12.530080</th>\n",
       "    <th>4.677897</th>\n",
       "    <th>2.618353</th>\n",
       "    <th>6.767543</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>74</th>\n",
       "    <th>12.567195</th>\n",
       "    <th>4.678077</th>\n",
       "    <th>2.630571</th>\n",
       "    <th>-inf</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>75</th>\n",
       "    <th>12.478121</th>\n",
       "    <th>4.667395</th>\n",
       "    <th>2.672491</th>\n",
       "    <th>6.691317</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>76</th>\n",
       "    <th>12.549046</th>\n",
       "    <th>4.691970</th>\n",
       "    <th>2.566294</th>\n",
       "    <th>6.848884</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>77</th>\n",
       "    <th>12.513264</th>\n",
       "    <th>4.678134</th>\n",
       "    <th>2.649951</th>\n",
       "    <th>6.735967</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>78</th>\n",
       "    <th>12.521555</th>\n",
       "    <th>4.664242</th>\n",
       "    <th>2.709657</th>\n",
       "    <th>6.647150</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>79</th>\n",
       "    <th>12.476468</th>\n",
       "    <th>4.684949</th>\n",
       "    <th>2.588950</th>\n",
       "    <th>6.811736</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>80</th>\n",
       "    <th>12.507753</th>\n",
       "    <th>4.680367</th>\n",
       "    <th>2.616412</th>\n",
       "    <th>6.774636</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>81</th>\n",
       "    <th>12.524096</th>\n",
       "    <th>4.687538</th>\n",
       "    <th>2.606961</th>\n",
       "    <th>6.798727</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>82</th>\n",
       "    <th>12.518260</th>\n",
       "    <th>4.673543</th>\n",
       "    <th>2.642750</th>\n",
       "    <th>6.734134</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>83</th>\n",
       "    <th>12.471395</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.629111</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>84</th>\n",
       "    <th>12.524637</th>\n",
       "    <th>4.687044</th>\n",
       "    <th>2.621300</th>\n",
       "    <th>6.783034</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>85</th>\n",
       "    <th>12.492899</th>\n",
       "    <th>4.679892</th>\n",
       "    <th>2.657823</th>\n",
       "    <th>6.731559</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>86</th>\n",
       "    <th>12.523358</th>\n",
       "    <th>4.673154</th>\n",
       "    <th>2.639856</th>\n",
       "    <th>6.736072</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>87</th>\n",
       "    <th>12.500896</th>\n",
       "    <th>4.683987</th>\n",
       "    <th>2.575829</th>\n",
       "    <th>-440167106084864.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>88</th>\n",
       "    <th>12.513809</th>\n",
       "    <th>4.679745</th>\n",
       "    <th>2.626983</th>\n",
       "    <th>6.762670</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>89</th>\n",
       "    <th>12.533821</th>\n",
       "    <th>nan</th>\n",
       "    <th>2.733097</th>\n",
       "    <th>nan</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>90</th>\n",
       "    <th>12.501985</th>\n",
       "    <th>4.673594</th>\n",
       "    <th>2.654728</th>\n",
       "    <th>-544333484785664.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>91</th>\n",
       "    <th>12.497383</th>\n",
       "    <th>4.672987</th>\n",
       "    <th>2.645108</th>\n",
       "    <th>6.730461</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>92</th>\n",
       "    <th>12.523682</th>\n",
       "    <th>4.684688</th>\n",
       "    <th>2.607962</th>\n",
       "    <th>-15781497667584.000000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>93</th>\n",
       "    <th>12.530644</th>\n",
       "    <th>4.674960</th>\n",
       "    <th>2.648115</th>\n",
       "    <th>6.731248</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>94</th>\n",
       "    <th>12.472159</th>\n",
       "    <th>4.657613</th>\n",
       "    <th>2.730952</th>\n",
       "    <th>6.612217</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>95</th>\n",
       "    <th>12.518738</th>\n",
       "    <th>4.662062</th>\n",
       "    <th>2.745997</th>\n",
       "    <th>6.605852</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>96</th>\n",
       "    <th>12.522870</th>\n",
       "    <th>4.682864</th>\n",
       "    <th>2.609443</th>\n",
       "    <th>6.786636</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>97</th>\n",
       "    <th>12.523118</th>\n",
       "    <th>4.699108</th>\n",
       "    <th>2.530765</th>\n",
       "    <th>6.899439</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>98</th>\n",
       "    <th>12.485676</th>\n",
       "    <th>4.673411</th>\n",
       "    <th>2.664243</th>\n",
       "    <th>6.712050</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>99</th>\n",
       "    <th>12.526973</th>\n",
       "    <th>4.687445</th>\n",
       "    <th>2.599023</th>\n",
       "    <th>6.806383</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>100</th>\n",
       "    <th>12.495291</th>\n",
       "    <th>4.682745</th>\n",
       "    <th>2.618155</th>\n",
       "    <th>6.777697</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_lr = 1e-4\n",
    "lrs = [max_lr/20, max_lr/5, max_lr]\n",
    "learn.fit_one_cycle(100, lrs, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21e0ae2a6cc37dd5a53215cde165949eac5ec165"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd33bbeb2f61393ba0fa162e5c95359cd88e3aed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b8151ae994dc88eee113caf9d445ba29f28bb88"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
